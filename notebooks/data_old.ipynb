{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the data processing script for POP909: A Pop song Dataset for Music Arrangement Generation.\n",
    "\n",
    "It will allow you to quickly process the POP909 Files (Midi) into the Google Magenta's music representation \n",
    "as in [Music Transformer](https://magenta.tensorflow.org/music-transformer) and\n",
    "[Performance RNN](https://magenta.tensorflow.org/performance-rnn).\n",
    "\n",
    "Modified from: https://github.com/music-x-lab/POP909-Dataset/blob/master/data_process/data_process.ipynb\n",
    "\n",
    "Note: I'm not using this data representation anymore. This notebook is just included for potential future use.\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import pypianoroll\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util import MidiEventProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Chord:\n",
    "    name: str\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    token: int\n",
    "    chord: Chord\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Segment:\n",
    "    chord_token: int\n",
    "    event_tokens: list\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    chords: list\n",
    "    events: list\n",
    "\n",
    "\n",
    "class ChordVocab:\n",
    "    def __init__(self, chords):\n",
    "        self.chords = chords.copy()\n",
    "        self.chord_to_token = {chord: i for i, chord in enumerate(chords)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_chords(data_root):\n",
    "    chords = set()\n",
    "    for song_idx in sorted(os.listdir(data_root)):\n",
    "        song_dir = os.path.join(data_root, song_idx)\n",
    "        if not os.path.isdir(song_dir):\n",
    "            continue\n",
    "        chord_path = os.path.join(song_dir, \"chord_midi.txt\")\n",
    "        with open(chord_path, newline=\"\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\")\n",
    "            chord_data = list(reader)\n",
    "        for _, _, chord in chord_data:\n",
    "            chords.add(chord)\n",
    "    return chords\n",
    "\n",
    "\n",
    "def make_chord_vocab(data_root, out_path):\n",
    "    unique_chords = list(get_unique_chords(data_root))\n",
    "    unique_chords.sort()\n",
    "    unique_chords.remove(\"N\")\n",
    "    unique_chords.insert(0, \"N\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for chord in unique_chords:\n",
    "            f.write(f\"{chord}\\n\")\n",
    "\n",
    "\n",
    "def load_chord_vocab(vocab_path):\n",
    "    with open(vocab_path, \"r\") as f:\n",
    "        chords = f.read().splitlines()\n",
    "    return ChordVocab(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_chord_vocab(\"../pop909/original\", \"../pop909/chord_vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_vocab = load_chord_vocab(\"../pop909/chord_vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_song(midi_path, chord_path, chord_vocab):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    \n",
    "    assert midi_data.instruments[0].name == \"MELODY\"\n",
    "    assert midi_data.instruments[1].name == \"BRIDGE\"\n",
    "    assert midi_data.instruments[2].name == \"PIANO\"\n",
    "    \n",
    "    melody = midi_data.instruments[0].notes\n",
    "    bridge = midi_data.instruments[1].notes\n",
    "    piano = midi_data.instruments[2].notes\n",
    "\n",
    "    notes = melody + bridge + piano\n",
    "    notes.sort(key=lambda note: note.start)\n",
    "    \n",
    "    with open(chord_path, newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        chord_data = list(reader)\n",
    "\n",
    "    chords = [\n",
    "        Chord(chord, float(start_time), float(end_time))\n",
    "        for start_time, end_time, chord in chord_data\n",
    "    ]\n",
    "    mep = MidiEventProcessor()\n",
    "    events = mep.encode(notes, chords)\n",
    "\n",
    "    segments = []\n",
    "    for chord in chords:\n",
    "        event_tokens = [e.token for e in events if e.chord is chord]\n",
    "        chord_token = chord_vocab.chord_to_token[chord.name]\n",
    "        segment = Segment(chord_token, event_tokens)\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "\n",
    "def preprocess_pop909(data_root, chord_vocab_path, out_dir):\n",
    "    chord_vocab = load_chord_vocab(chord_vocab_path)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for song_idx in tqdm(sorted(os.listdir(data_root))):\n",
    "        song_dir = os.path.join(data_root, song_idx)\n",
    "        if not os.path.isdir(song_dir):\n",
    "            continue\n",
    "        midi_path = os.path.join(song_dir, f\"{song_idx}.mid\")\n",
    "        chord_path = os.path.join(song_dir, \"chord_midi.txt\")\n",
    "        segments = preprocess_song(midi_path, chord_path, chord_vocab)\n",
    "        out_path = os.path.join(out_dir, f\"{song_idx}.pkl\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            pickle.dump(segments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 910/910 [03:42<00:00,  4.10it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_pop909(\n",
    "    data_root=\"../pop909/original\",\n",
    "    chord_vocab_path=\"../pop909/chord_vocab.txt\",\n",
    "    out_dir=\"../pop909/processed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(iterable, n, fillvalue=None):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    >>> group(\"ABCDEFG\", 3, \"x\")\n",
    "    ABC DEF Gxx\n",
    "    \n",
    "    Source: https://docs.python.org/3/library/itertools.html.\n",
    "    \"\"\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "def get_chunks(path, n=4, eos_token=356):\n",
    "    \"\"\"\n",
    "    Create a list of chunks, i.e. {chord_tokens, event_tokens} pairs,\n",
    "    from a file containing the segments of a song.\n",
    "    \n",
    "    Also append an end-of-sequence token to every sequence of event\n",
    "    tokens.\n",
    "    \n",
    "    Args:\n",
    "        path: The path to the source file.\n",
    "        n: The number of segments per data point.\n",
    "    \"\"\"\n",
    "    segments = pickle.load(open(path, \"rb\"))\n",
    "    segments = filter(lambda s: len(s.event_tokens) > 0, segments)\n",
    "    chunks = []\n",
    "    for segment_group in group(segments, n):\n",
    "        if None in segment_group:\n",
    "            continue\n",
    "        chord_tokens = [s.chord_token for s in segment_group]\n",
    "        event_tokens = []\n",
    "        for s in segment_group:\n",
    "            event_tokens.extend(s.event_tokens)\n",
    "        event_tokens.append(eos_token)\n",
    "        chunk = Chunk(chords=chord_tokens, events=event_tokens)\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_all_chunks(data_root, n=4):\n",
    "    \"\"\"\n",
    "    Get the chunks from all songs and combine them.\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    for file_name in sorted(os.listdir(data_root)):\n",
    "        if not file_name.endswith(\".pkl\"):\n",
    "            continue\n",
    "        path = os.path.join(data_root, file_name)\n",
    "        chunks = get_chunks(path, n)\n",
    "        all_chunks.extend(chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_all_chunks(\"../pop909/processed\")\n",
    "with open(\"../pop909/pop909.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset of chunks from songs. Each chunk consists of a sequence of\n",
    "    4 chords along with a sequence of notes played with those chords.\n",
    "    \n",
    "    The chords and the notes are both tokenized already, and converted to\n",
    "    tensors when __getitem__ is called.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "\n",
    "        data = pickle.load(open(data_path, \"rb\"))\n",
    "        self._chords = [torch.LongTensor(d.chords) for d in data]\n",
    "        self._events = [torch.LongTensor(d.events) for d in data]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._chords)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self._chords[idx],\n",
    "            self._events[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MusicDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0005b37f9cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMusicDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../pop909/pop909.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MusicDataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = MusicDataset(\"../pop909/pop909.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens = [len(d[1]) for d in dataset]\n",
    "print(max(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(seq_lens, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
